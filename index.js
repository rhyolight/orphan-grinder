var async = require('async')
  , scraper = require('./scraper')
  , argv = require('minimist')(process.argv.slice(2))
  , url
  , verbose = false
  , all = false
  , debug = false
  , now = new Date()
  ;

function printHelp() {
    console.log('\nOrphan Grinder Usage');
    console.log('====================');
    console.log('  node index.js <wiki-url> [options]');
    console.log('\nOptions:');
    console.log('  --verbose prints info about HTTP calls');
    console.log('  --all     prints info about found links as well as orphans');
    console.log('  --debug=N only fetches the first N wiki pages in the index');
}

function processArgs(args) {
    url = args._[0];
    commandArgs = args._.slice(1);
    if (args.help) {
        printHelp();
        process.exit();
    }
    if (! url) {
        console.error('\nNo wiki url was specified!');
        printHelp();
        process.exit(-1);
    }
    all = args.all;
    verbose = args.verbose;
    debug = args.debug;
}

function report(linkTracks, badLinks) {
    var orphaned = []
      , orderedPages = []
      ;
    _.each(linkTracks, function(links, page) {
        if (! links.length) {
            orphaned.push(page);
        }
        orderedPages.push({name: page, links: links});
    });
    orderedPages = _.sortBy(orderedPages, function(op) {
        return op.links.length;
    }).reverse();

    console.log('\n');
    console.log('# Orphan Grinder Report');
    console.log('\n> This report was generated by <https://github.com/rhyolight/orphan-grinder> for %s on %s.', url, now);

    console.log('\n');
    console.log('## Orphaned Pages (%s):\n', orphaned.length);
    _.each(orphaned, function(orphan) {
        console.log('- [%s](%s)', orphan, orphan);
    });

    if (all) {
        console.log('\n');
        console.log('## Most Linked Pages\n');
        _.each(orderedPages.slice(0, 10), function(op) {
            console.log('- [%s](%s) (%s links)', op.name, op.name, op.links.length);
        });

        console.log('\n');
        console.log('## All Linked Pages:\n');
        _.each(orderedPages, function(op) {
            if (op.links.length) {
                console.log('- [%s](%s) is linked from:', op.name, op.name);
                _.each(op.links, function(link) {
                    console.log('  - [%s](%s)', link, link);
                });
            }
        });
    }

    if (badLinks.length && badLinks.length) {
        console.log('\n');
        console.log('## BAD LINKS (%s):\n', badLinks.length);
        _.each(badLinks, function(badLink) {
            console.log('- [%s](%s) ==> `%s`', badLink[0], badLink[0], badLink[1]);
        });
    }
}

function scrapeWiki(wikiUrl) {
    console.log('***********************************************************');
    console.log('** Starting scrape of %s', wikiUrl);
    console.log('***********************************************************');
    console.log('\nLooking up wiki page index...');
    scraper.getAllWikiPages(wikiUrl, verbose, function(err, pages) {
        var linkTracks = {}
          , badLinks = []
          , failedLoads = []
          , pageFetchers = {}
          , processedPageCount = 0;

        if (err) {
            return console.error(err);
        }

        if (debug) {
            pages = pages.slice(0, debug);
        }

        console.log('Scraping %s wiki pages...', pages.length);
        
        _.each(pages, function(page) {
            linkTracks[page] = [];
        });

        function createWikiPageFetcher(pageName) {
            return function(callback) {
                var pageUrl = wikiUrl + '/' + pageName;
                scraper.scrapeWikiLinks(pageUrl, verbose, function(err, links) {
                    if (err) {
                        failedLoads.push(pageName);
                    } else {
                        _.each(links, function(link) {
                            if (link) {
                                if (!linkTracks[link]) {
                                    badLinks.push([pageName, link]);
                                } else {
                                    linkTracks[link].push(pageName);
                                }
                            }
                        });
                        processedPageCount++;
                        if (processedPageCount % 10 == 0) {
                            console.log('%s% done... %s pages processed, %s to go...', (Math.round((processedPageCount / pages.length) * 100)), processedPageCount, (pages.length - processedPageCount));
                            console.log('\t(%s failed page loads, %s bad links)', failedLoads.length, badLinks.length);
                        }
                    }
                    callback();
                });
            };
        }

        _.each(pages, function(pageName) {
            pageFetchers[pageName] = createWikiPageFetcher(pageName);
        });

        function executeFetchers(fetchers, callback) {
            async.parallelLimit(fetchers, 10, function(err) {
                var loadFailures = [];
                if (err) {
                    callback(err);
                } else if (failedLoads.length) {
                    while (failedLoads.length) {
                        loadFailures.push(createWikiPageFetcher(failedLoads.shift()));
                    }
                    console.log('Re-fetching %s URLs...', loadFailures.length);
                    executeFetchers(loadFailures, callback);
                } else {
                    report(linkTracks, badLinks, failedLoads);
                }
            });

        };

        executeFetchers(pageFetchers, function(err) {
            if (err) {
                console.error("ERROR");
                console.error(err);
            } else {
                report(linkTracks, badLinks);
            }
        });

    });    
}

processArgs(argv);
scrapeWiki(url);


